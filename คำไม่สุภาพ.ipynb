{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ผลลัพธ์ที่ควรได้\n",
        "text : ข้อความแสดงความคิดเห็นที่ทำการวิเคราะห์\n",
        "\n",
        "bully_word : ผลลัพธ์ซึ่งเป็นคำที่แสดงออกถึงการรังแกที่พบในข้อความ\n",
        "\n",
        "bully_type : ผลจากการวิเคราะห์ความคิดเห็นว่าเป็นข้อความที่มีลักษณะของการรังแก (bullying) ประเภทไหน\n",
        "\n",
        " 0: ข้อความทั่วไปซึ่งไม่มีลักษณะของการรังแก\n",
        "\n",
        " 1: ข้อความที่มีการกล่าวถึงบุคลิก รูปลักษณ์ และ พฤติกรรม\n",
        "\n",
        " 2: ข้อความที่เป็นคำด่า คำหยาบคาย\n",
        "\n",
        " 3: ข้อความคุกคามเกี่ยวกับทางเพศ\n",
        "\n",
        " 4: ข้อความที่กล่าวถึง เชื้อชาติ กำเนิด และการใช้ชีวิต\n",
        "\n",
        " 5: ข้อความที่กล่าวถึงสติปัญญา และความฉลาด\n",
        "\n",
        " 6: ข้อความที่มีการใช้ถ้อยคำรุนแรง การข่มขู่"
      ],
      "metadata": {
        "id": "oGuCLSMydU_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#คำหยาบ,ไม่สุภาพ"
      ],
      "metadata": {
        "id": "UxIMGq_CgPY6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CESsR5hPbvPe",
        "outputId": "966d59c9-3484-45cf-9f19-299179bfe9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Response: {'text': 'แม่งเอ๊ย วันนี้ก็รีบแทบตาย รถก็ติดเป็นบ้า หัวหน้าก็ดันโทรมาจิกงานตอนกำลังจะขึ้นรถไฟฟ้าอีก โคตรเซ็งเลย กูแทบอยากปาข้าวกล่องทิ้งแม่งตรงนั้นแหละ!', 'bully_word': ['แม่ง', 'โคตร', 'กู'], 'bully_type': [2]}\n",
            "พบคำหยาบทั้งหมด: 3\n",
            "คะแนน: 0\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \" https://api.aiforthai.in.th/bully\"\n",
        "\n",
        "text = '''แม่งเอ๊ย วันนี้ก็รีบแทบตาย รถก็ติดเป็นบ้า หัวหน้าก็ดันโทรมาจิกงานตอนกำลังจะขึ้นรถไฟฟ้าอีก โคตรเซ็งเลย กูแทบอยากปาข้าวกล่องทิ้งแม่งตรงนั้นแหละ!'''\n",
        "\n",
        "data = {'text':text}\n",
        "\n",
        "headers = {\n",
        "    'Apikey': \"PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af\",\n",
        "    }\n",
        "\n",
        "response = requests.post(url, data=data, headers=headers)\n",
        "\n",
        "result = response.json()\n",
        "\n",
        "# แสดงผลลัพธ์จาก API\n",
        "print(\"API Response:\", result)\n",
        "\n",
        "# ตรวจสอบและนับคำหยาบจากผล API\n",
        "bully_words = result.get(\"bully_word\", [])\n",
        "\n",
        "# นับคำหยาบ\n",
        "count = len(bully_words)\n",
        "print(\"พบคำหยาบทั้งหมด:\", count)\n",
        "\n",
        "# คำนวณคะแนน (ถ้าพบคำหยาบมากกว่าหรือเท่ากับ 2 คำ ได้ 0 ถ้าไม่ ได้ 2 คะแนน)\n",
        "score = 0 if count >= 2 else 2\n",
        "print(\"คะแนน:\", score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#กล่าวพาดพิงคนอื่น\n",
        "ตรวจให้ว่าได้ 0 คะแนนแต่ไม่โชว์คำ(bully_word)และประเภท(bully_type)ของคำที่บอกว่าผิด"
      ],
      "metadata": {
        "id": "wq0fxtUCiU58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \" https://api.aiforthai.in.th/bully\"\n",
        "\n",
        "text1 = \"วันก่อนฉันเห็นหล่อนไปเที่ยวกับสามีของคนอื่นมาดูสนิทกันเชียว ฉันว่าหล่อนต้องเป็นชู้แน่ๆเลย\"\n",
        "\n",
        "data = {'text':text1}\n",
        "\n",
        "headers = {\n",
        "    'Apikey': \"PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af\",\n",
        "    }\n",
        "\n",
        "response = requests.post(url, data=data, headers=headers)\n",
        "\n",
        "result = response.json()\n",
        "\n",
        "# แสดงผลลัพธ์จาก API\n",
        "print(\"API Response:\", result)\n",
        "\n",
        "# ตรวจสอบและนับคำหยาบจากผล API\n",
        "bully_words = result.get(\"bully_word\", [])\n",
        "\n",
        "# นับคำหยาบ\n",
        "count = len(bully_words)\n",
        "print(\"พบคำหยาบทั้งหมด:\", count)\n",
        "\n",
        "# คำนวณคะแนน (ถ้าพบคำหยาบมากกว่าหรือเท่ากับ 2 คำ ได้ 0 ถ้าไม่ ได้ 2 คะแนน)\n",
        "score = 0 if count >= 2 else 2\n",
        "print(\"คะแนน:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuoLFVl_gNnL",
        "outputId": "706b9739-3ad1-421f-c3ef-4925ad9bb396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Response: {'text': 'วันก่อนฉันเห็นหล่อนไปเที่ยวกับสามีของคนอื่นมาดูสนิทกันเชียว ฉันว่าหล่อนต้องเป็นชู้แน่ๆเลย', 'bully_word': 'None', 'bully_type': 0}\n",
            "พบคำหยาบทั้งหมด: 4\n",
            "คะแนน: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ต้องมี datasets ของคำสำหรับการพาดพิงหรือคำสรรพนามที่ใช้เรียกไม่เหมาะสมอยู่ดี"
      ],
      "metadata": {
        "id": "mZ3f_7XbkUER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# ===== ข้อความที่จะตรวจ =====\n",
        "text = \"วันก่อนฉันเห็นหล่อนไปเที่ยวกับสามีของคนอื่นมาดูสนิทกันเชียว ฉันว่าหล่อนต้องเป็นชู้แน่ๆเลย\"\n",
        "\n",
        "# ===== ตั้งค่า API =====\n",
        "url = \"https://api.aiforthai.in.th/bully\"\n",
        "headers = {\n",
        "    'Apikey': \"PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af\",\n",
        "}\n",
        "data = {'text': text}\n",
        "\n",
        "# ===== เรียก API =====\n",
        "response = requests.post(url, data=data, headers=headers)\n",
        "result = response.json()\n",
        "\n",
        "# ===== เช็กผลจาก API =====\n",
        "bully_types = result.get(\"bully_type\", 0)\n",
        "bully_count = 1 if bully_types != 0 else 0\n",
        "print(\"ประเภทคำรุนแรงจาก API:\", bully_types)\n",
        "\n",
        "# ===== ตรวจพาดพิงบุคคล =====\n",
        "def detect_reference(text):\n",
        "    pronouns = [\"มัน\", \"เขา\", \"หล่อน\", \"นาง\", \"ไอ้\", \"อีนั่น\", \"พวกมัน\", \"สามีของคนอื่น\"]\n",
        "    return [word for word in pronouns if word in text]\n",
        "\n",
        "# ===== ตรวจคำกล่าวหา =====\n",
        "def detect_accusation(text):\n",
        "    accusations = [\"เป็นชู้\", \"ขโมย\", \"โกง\", \"หลอก\", \"เลว\", \"นอกใจ\", \"แย่งผัว\", \"ทำลายชื่อเสียง\"]\n",
        "    return [word for word in accusations if word in text]\n",
        "\n",
        "references = detect_reference(text)\n",
        "accusations = detect_accusation(text)\n",
        "\n",
        "print(\"คำพาดพิงที่พบ:\", references)\n",
        "print(\"คำกล่าวหาที่พบ:\", accusations)\n",
        "\n",
        "# ===== ตัดสินคะแนน =====\n",
        "# กรณีให้ 0 คะแนน ถ้ามีคำหยาบ >= 2 หรือ พาดพิง + กล่าวหา\n",
        "score = 1  # เริ่มจาก 1\n",
        "\n",
        "if bully_count >= 2 or (references and accusations):\n",
        "    score = 0\n",
        "\n",
        "print(\"คะแนนที่ได้:\", score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7IYWc9Ejp8z",
        "outputId": "26ef3f11-31d6-4a3c-d97a-a88c6e0b5acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ประเภทคำรุนแรงจาก API: 0\n",
            "คำพาดพิงที่พบ: ['หล่อน', 'สามีของคนอื่น']\n",
            "คำกล่าวหาที่พบ: ['เป็นชู้']\n",
            "คะแนนที่ได้: 0\n"
          ]
        }
      ]
    }
  ]
}